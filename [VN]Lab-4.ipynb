{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"[VN]Lab-4.ipynbL","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"VVUKL7jIMH33"},"source":["# Hồi quy Ridge Regression (diễn giải)"]},{"cell_type":"markdown","metadata":{"id":"0vrMMNPMMH38"},"source":["Trong notebook này, chúng ta sẽ chạy hồi quy Ridge nhiều lần với các L2 penalty khác nhau để xem cái nào sẽ khớp tốt nhất. Chúng ta sẽ tham khảo lại ví dụ hồi quy đa thức để thấy được hiệu quả của điều chuẩn L2.\n","* Sử dụng triển khai được tích hợp sẵn của Hồi quy Ridge từ sklearn để chạy hồi quy đa thức.\n","* Sử dụng matplotlib để trực quan hóa hồi quy đa thức.\n","* Sử dụng triển khai trên để chạy hồi quy đa thức, lần này là với L2 penalty.\n","* Sử dụng matplotlib để trực quan hóa hồi quy đa thức với điều chuẩn L2.\n","* Chọn L2 penalty tốt nhất sử dụng kiểm định chéo.\n","* Đánh giá khớp cuối cùng sử dụng dữ liệu kiểm tra.\n","\n","Chúng ta sẽ tiếp tục sử dụng dữ liệu giá nhà từ các notebook trước đó. (Trong bài tập lập trình tiếp theo, chúng ta sẽ triển khai thuật toán học hồi quy Ridge với gradient descent.)"]},{"cell_type":"markdown","metadata":{"id":"VcfzkQ2PMH3-"},"source":["## Thư viện"]},{"cell_type":"code","metadata":{"id":"W20HLZsEMH4B"},"source":["import sklearn, pandas\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kk_-_EC-MH4M"},"source":["## Hồi quy đa thức"]},{"cell_type":"markdown","metadata":{"id":"THfgTOGiMH4P"},"source":["Chúng ta sẽ lấy nguồn từ lab trước (*lab-3.ipynb*), đã có hàm tạo DataFrame với các cột chứa lũy thừa của một đầu vào đã biết. Copy và paste hàm `polynomial_dataframe`:"]},{"cell_type":"code","metadata":{"id":"35ETgMu4MH4T"},"source":["def polynomial_dataframe(feature, degree):\n","    # \n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xR4cfYlIMH4f"},"source":["Chúng ta sẽ dùng matplotlib để hiển thị xem hồi quy đa thức trông như thế nào với dữ liệu nhà ở."]},{"cell_type":"code","metadata":{"id":"06SszSocMH4k"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GB7vW5nMH4v"},"source":["full_data = pandas.read_csv(\"kc_house_data.csv\", index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P800G-jSMH45"},"source":["Ở lab trước, chúng ta đã dùng biến 'sqft_living'. Để vẽ biểu đồ (nối các chấm), chúng ta cần sắp xếp theo theo giá trị 'sqft_living'; với các ngôi nhà có cùng diện tích, chúng ta sẽ chọn theo giá."]},{"cell_type":"code","metadata":{"id":"45kD_iqOMH47"},"source":["full_data = full_data.sort_values(['sqft_living', 'price'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"glxnRQIvMH5D"},"source":["Hãy xem lại  mô hình đa thức bậc 15 sử dụng đầu vào 'sqft_living'. Tạo các đặc trưng đa thức bậc 15 sử dụng `polynomial_dataframe()` và khớp mô hình với các đặc trưng này, sử dụng L2 penalty của `1e-5`:"]},{"cell_type":"code","metadata":{"id":"ifNuc9vyMH5F"},"source":["l2_small_penalty = 1e-5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7N5PNVAKMH5O"},"source":["\n","Lưu ý: Nếu có quá nhiều đặc trưng và quá ít điểm dữ liệu, giải pháp có thể không ổn định về mặt số học, đôi khi có thể dẫn đến các kết quả kỳ lạ không thể đoán trước. Do đó, thay vì không sử dụng điều chuẩn, chúng ta sẽ đưa vào một ít điều chuẩn (`l2_penalty=1e-5`) để làm cho giải pháp ổn định về mặt số học. (Trong bài giảng, chúng ta đã thảo luận là điều chuẩn cũng có thể giúp ổn định số, ở đây chúng ta có một ví dụ thực tế.)\n","\n","Với L2 penalty trên, hãy khớp mô hình và in ra các trọng số tìm được. Có thể tham khảo [Hồi quy Ridge của sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html).\n","\n","Chúng ta cũng có thể chuẩn hóa các giá trị cho phân phối Gauss qua [StandardScaler của sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), vì các giá trị penalty điều chỉnh độ lớn của trọng số, tỷ lệ nghịch với các giá trị đa thức (rất lớn).  "]},{"cell_type":"code","metadata":{"id":"VCYXQCIPMH5Q"},"source":["from sklearn.linear_model import Ridge, LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","# Mức độ trợ giúp: vừa phải\n","scaler = StandardScaler()\n","poly_data = polynomial_dataframe(full_data['sqft_living'], 15)\n","poly_features = scaler.fit_transform(poly_data.values)\n","# hãy tự thực hiện tiếp\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rf9haUEmMH5d"},"source":["***QUIZ:  Giá trị tìm được cho các hệ số của đặc trưng `power_1` là?***"]},{"cell_type":"markdown","metadata":{"id":"JB7ZkhDWMH5g"},"source":["# Quan sát overfitting"]},{"cell_type":"markdown","metadata":{"id":"33LxBDqbMH5l"},"source":["\n","Theo lab trước, khớp đa thức bậc 15 thay đổi rất nhiều mỗi khi dữ liệu thay đổi. Cụ thể, khi chúng ta chia dữ liệu bán nhà thành 4 tập con và khớp mô hình bậc 15 thì kết quả của mỗi tập con lại khác; mô hình có *phương sai cao*. Chúng ta sẽ thấy ngay sau đây, hồi quy Ridge sẽ giảm phương sai đó. Nhưng trước tiên, chúng ta cần tái hiện lại những gì đã làm."]},{"cell_type":"markdown","metadata":{"id":"IYinkpENMH5n"},"source":["Trước tiên, chia dữ liệu thành 4 tập con có kích thước tương tự nhau và gọi chúng là `set_1`, `set_2`, `set_3`, và `set_4`. Sử dụng hàm `train_test_split` và thiết lập `random_state=0`. "]},{"cell_type":"code","metadata":{"id":"dU9EfuonMH5o"},"source":["from sklearn.model_selection import train_test_split\n","seed = 20\n","big_set_1, big_set_2 = train_test_split(full_data, train_size=0.5, test_size=0.5, random_state=0)\n","set_1, set_2 = train_test_split(big_set_1, train_size=0.5, test_size=0.5, random_state=0)\n","set_3, set_4 = train_test_split(big_set_2, train_size=0.5, test_size=0.5, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tUMvZSMOMH5t"},"source":["Tiếp theo, khớp đa thức bậc 15 trong `set_1`, `set_2`, `set_3` và `set_4`, sử dụng 'sqft_living' để đoán giá. In các trọng số và vẽ biểu đồ mô hình kết quả."]},{"cell_type":"code","metadata":{"id":"FKafX2vyMH5w"},"source":["# Chúng ta khớp sử dụng LinearRegression."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"oYl_V_jwMH55"},"source":["# Có thể copy từ lab trước"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRvMoJ_rMH5-"},"source":["# Copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw-QEwOIMH6I"},"source":["# Đừng quên quiz bên dưới."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BHXGHFkYMH6O"},"source":["4 đồ thị cần khác nhau theo các hệ số đã thấy.\n","\n","***QUIZ:  Với các mô hình đã thấy trong mỗi tập huấn luyện, gía trị tuyệt đối nhỏ nhất và lớn nhất cho hệ số của đặc trưng `power_1` là?***"]},{"cell_type":"markdown","metadata":{"id":"VoPtjmQnMH6R"},"source":["# Hồi quy Ridge"]},{"cell_type":"markdown","metadata":{"id":"KIWDTF17MH6S"},"source":["Nhìn chung, bất cứ khi nào thấy trọng số thay đổi quá nhiều đế đáp ứng thay đổi trong dữ liệu thì phương sai của ước tính cũng lớn. Hồi quy Ridge giúp giải quyết vấn đề này bằng cách phạt các trọng số \"lớn\" (Các trọng số của `model15` trông khá nhỏ nhưng chúng không hề nhỏ vì đầu vào 'sqft_living' theo đơn vị hàng nghìn).\n","\n","Với đối số `l2_penalty=1e3`, hãy khớp mô hình đa thức bậc 15 trong `set_1`, `set_2`, `set_3` và `set_4`. Ngoài thay đổi trong `l2_penalty`, code <u>cũng cần tương tự</u> như phép thử trên."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"MGol3bQWMH6T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"34zUlob1MH6Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLll4AbHMH6g"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miFqMNCXMH6o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cZ-xpdVfMH6u"},"source":["Các đồ thị thay đổi khá ít, giờ hãy áp dụng điều chuẩn bậc cao hơn.\n","\n","***QUIZ:  Với các mô hình đã thấy có điều chuẩn mức độ cao hơn trong từng tập huấn luyện, giá trị nhỏ nhất và lớn nhất cho hệ số của đặc trưng `power_1` là bao nhiêu?*** (Với câu này, các số âm nhỏ hơn số dương, chẳng hạn: -5 < -3 < 5,..)"]},{"cell_type":"markdown","metadata":{"id":"wugqYf-MMH6w"},"source":["## Chọn L2 penalty qua kiểm định chéo "]},{"cell_type":"markdown","metadata":{"id":"dzT-BhisMH6x"},"source":["Cũng giống như bậc đa thức, L2 penalty là tham số mà chúng ta cần lựa chọn. Chúng ta có thể sử dụng tập kiểm định như đã làm trước đó, nhưng cách tiếp cận này có một nhược điểm lớn: nó để lại ít quan sát hơn cho việc huấn luyện. **Kiểm định chéo** khắc phục vấn đề này bằng cách sử dụng tất cả các tập huấn luyện một cách thông minh.\n","\n","Chúng ta sẽ triển khai một loại kiểm định chéo là **kiểm định chéo k-fold**. Phương thức này có tên như vậy vì nó liên quan đến việc chia tập huấn luyện thành k segment (phân đoạn) có kích thước như nhau. Tương tự như phương pháp tập kiểm định, chúng ta đo lỗi kiểm định với một trong các phân đoạn được chỉ định làm tập kiểm định. Khác biệt chính là chúng ta lặp lại quy trình k lần như sau:\n","\n","Đặt segment 0 là tập kiểm định, khớp mô hình với các dữ liệu còn lại và đánh giá nó trên tập kiểm định này.<br>\n","Đặt segment 1 là tập kiểm định, khớp mô hình với các dữ liệu còn lại và đánh giá nó trên tập kiểm định này.<br>\n","...<br>\n","Đặt segment k-1 là tập kiểm định, khớp mô hình với các dữ liệu còn lại và đánh giá nó trên tập kiểm định này.\n","\n","Sau quá trình này, chúng ta tính giá trị trung bình của k lỗi kiểm định và sử dụng nó để ước tính sai số tổng quát hóa. Lưu ý rằng tất cả các quan sát được sử dụng cho cả huấn luyện và kiểm định khi lặp lại các phân đoạn dữ liệu.\n","\n","Để ước tính tốt sai số tổng quát hóa, cần xáo trộn dữ liệu huấn luyện trước khi chia chúng thành các segment. Sklearn có hàm shuffle nên chúng ta sẽ sử dụng hàm này. "]},{"cell_type":"code","metadata":{"id":"HXnQwfyoMH61"},"source":["train_and_validation, test_data = train_test_split(full_data, train_size=0.9, test_size=0.1, random_state=1)\n","train_and_validation = sklearn.utils.shuffle(train_and_validation, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ayYvIzSYMH66"},"source":["Khi dữ liệu đã được xáo trộn, chúng ta sẽ chia nó thành các segment bằng nhau, mỗi segment sẽ nhận `n/k` phần tử, trong đó `n` là số lượng quan sát trong tập huấn luyện còn `k` là số lượng segment. Do segment 0 bắt đầu tại chỉ mục 0 và chứa `n/k` phần tử nên nó sẽ chấm dứt ở chỉ mục `(n/k)-1`. Segment 1 bắt đầu tại vị trí của segment 0 ở chỉ mục `(n/k)`.Với `n/k` phần tử, segment 1 ngừng ở chỉ mục `(n*2/k)-1`. Tiếp tục cho tới chỉ mục `i` bắt đầu tại chỉ mục `(n*i/k)` và ngừng ở `(n*(i+1)/k)-1`."]},{"cell_type":"markdown","metadata":{"id":"RAQD4ox1MH67"},"source":["Với mô hình này, chúng ta viết một vòng lặp ngắn in các chỉ số bắt đầu và kết thúc của mỗi segment để đảm bảo chúng ta đang thực hiện đúng các phân tách."]},{"cell_type":"code","metadata":{"id":"dheyb20lMH68"},"source":["n = len(train_and_validation)\n","k = 10 # kiểm định chéo 10-fold \n","\n","for i in range(k):\n","    start = (n*i)//k\n","    end = (n*(i+1))//k-1\n","    print(i, (start, end))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SCWf-zc0MH7D"},"source":["Một trong những ưu điểm của thư viện dữ liệu nói chung là khả năng chấp nhận các slice. Để trích xuất một slice liên tục từ DataFrame, hãy sử dụng dấu hai chấm \":\" trong dấu ngoặc vuông \"[]\". Ví dụ: cell sau đây trích xuất các hàng từ 0 đến 9 của `train_and_validation`. Lưu ý rằng chỉ mục đầu tiên (0) được chứa trong slice nhưng chỉ mục cuối cùng (10) bị bỏ qua."]},{"cell_type":"code","metadata":{"id":"d1OlHZH9MH7E"},"source":["train_and_validation[0:10] # rows 0 to 9"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BVejNgM7MH7K"},"source":["Giờ hãy trích xuất segment riêng với cắt mảng. Chúng ta nhóm các ngôi nhà trong dataframe `train_and_validation` thành k=10 segment có kích thước như nhau với chỉ mục đầu và kết thúc được tính như trên. Trích xuất segment thứ 4 (segment 3) và gán nó cho biến `validation4`. "]},{"cell_type":"code","metadata":{"id":"rEYQLIo3MH7L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpbBFCx5MH7R"},"source":["\n","Để xác minh rằng chúng ta đã trích xuất đúng các phần tử, hãy chạy cell sau, cell này sẽ tính giá trung bình của segment thứ tư. Khi làm tròn đến số nguyên gần nhất, giá trị trung bình sẽ là 544,330 USD."]},{"cell_type":"code","metadata":{"id":"PkXCYyxYMH7T"},"source":["print( round(validation4['price'].mean(), 0) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJPG1EaHMH7Y"},"source":["Sau khi chỉ định một trong k segment làm tập kiểm định, chúng ta huấn luyện một mô hình với dữ liệu còn lại. Để chọn phần còn lại, chúng ta cắt (0:start) và (end+1:n) của dữ liệu và paste chúng lại với nhau. DataFrame có phương thức `append()` paste hai tập hợp hàng rời rạc từ một tập dữ liệu chung. Ví dụ: cell sau sẽ paste hàng đầu tiên và cuối cùng của dataframe `train_and_validation`."]},{"cell_type":"code","metadata":{"id":"qao1cWIWMH7a"},"source":["n = len(train_and_validation)\n","first_two = train_and_validation[0:2]\n","last_two = train_and_validation[n-2:n]\n","print(first_two.append(last_two))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PcQb83MxMH7f"},"source":["Trích xuất phần dữ liệu còn lại sau khi đã *loại trừ* segment thứ 4 (segment 3) và gán tập con cho `train4`."]},{"cell_type":"code","metadata":{"id":"NHBeNdXNMH7i"},"source":["# segment thứ 4 bắt đầu và kết thúc ở đâu? .append có tác dụng gì? "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9gwRZPGKMH7o"},"source":["Để xác minh rằng chúng ta đã trích xuất đúng các phần tử, hãy chạy cell sau, cell này sẽ tính giá trung bình của segment thứ tư. Khi làm tròn đến số nguyên gần nhất, giá trị trung bình sẽ là 540,120 USD."]},{"cell_type":"code","metadata":{"id":"bzsyZHH6MH7s"},"source":["print( round(train4['price'].mean(), 0) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JHkgU6KyMH7x"},"source":["Chúng ta đã sẵn sàng để triển khai kiểm định chéo k-fold. Viết một hàm tính k lỗi kiểm định bằng cách chỉ định từng segment trong số k segment làm tập kiểm định. Nó chấp nhận dưới dạng các tham số (i) `k`, (ii) `l2_penalty`, (iii) dataframe, (iv) tên của cột đầu ra (ví dụ: `price`) và (v) danh sách tên các đặc trưng. Hàm trả về lỗi kiểm định trung bình bằng cách sử dụng k segment làm tập kiểm định.\n","\n","* Với từng i trong [0, 1, ..., k-1]:\n","  * Tính chỉ mục bắt đầu và kết thúc của segment i và gọi 'start' và 'end'\n","  * Tạo tập kiểm định bằng cách lấy slice (start:end+1) từ dữ liệu.  \n","  * Tạo tập kiểm định bằng cách nối slice (end+1:n) với cuối của slice (0:start). \n","  * Huấn luyện mô hình tuyến tính dùng tập huấn luyện vừa tạo với l2_penalty đã cho. \n","  * Tính lỗi kiểm định sử dụng tập kiểm định vừa tạo. \n","\n","Sklearn cũng có hàm `mean_squared_error` tích hợp sẵn."]},{"cell_type":"code","metadata":{"id":"mYbI8bmyMH7z"},"source":["def k_fold_cross_validation(k, l2_penalty, data, output_name, features_list):\n","    # triển khai hàm.\n","    return mean_error"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zr2zhJrTMH75"},"source":["Chúng ta đã có một hàm tính toán lỗi kiểm định trung bình cho mô hình, hãy viết một vòng lặp để tìm mô hình tối thiểu hóa lỗi kiểm định trung bình, thực hiện như sau:\n","* Chúng ta sẽ khớp mô hình đa thức bậc 15 sử dụng đầu vào `sqft_living`.\n","* Với `l2_penalty` trong [10^0, 10^0.5, 10^1, 10^1.5, ..., 10^2] (trong Python, chúng ta sẽ dùng hàm Numpy sau: `np.logspace(0, 10, num=21)`.)\n","    * Chạy kiểm định chéo 10-fold với `l2_penalty`\n","* Báo lại L2 penalty nào cho lỗi kiểm định trung bình thấp nhất.\n","\n","Lưu ý: vì bậc của đa thức hiện được cố định là 15, để mọi thứ nhanh hơn, chúng ta hãy tạo các đặc trưng của đa thức trước và sử dụng lại chúng trong suốt vòng lặp. Hãy dùng `train_and_validation` khi tạo các đối tượng đa thức!\n","\n","Nếu thấy nhiều màu đỏ từ `scipy.linalg.solve`, hãy import `warnings` và sử dụng `warnings.filterwarnings('ignore')`. Đây không phải là phương pháp tốt nhất nhưng lại hữu ích. Sau khi đã hoàn tất, hãy đặt `warnings.resetwarnings()` để chuyển nó trở lại bình thường."]},{"cell_type":"code","metadata":{"id":"yydEZVn_MH77"},"source":["# Hãy thực hành\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HtOYofhRMH8G"},"source":["***QUIZ:  Giá trị tốt nhất cho L2 penalty theo kiểm định 10-fold là bao nhiêu?***"]},{"cell_type":"markdown","metadata":{"id":"7_Ii1d_YMH8I"},"source":["Sẽ rất hữu ích khi vẽ các lỗi kiểm định chéo k-fold mà chúng ta có được để hiểu rõ hơn cách xử lý của phương thức. Chúng ta cũng có thể dùng `plt.xscale('log')` cho biểu đồ trực quan. [Quitter.](https://xkcd.com/1162/)"]},{"cell_type":"code","metadata":{"id":"KxPQK30CMH8L"},"source":["# Vẽ các giá trị l2-penalty (có thể trong log) trên trục x và lỗi kiểm định chéo trên trục y\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J7ZjNm7DMH8T"},"source":["Khi đã tìm thấy giá trị tốt nhất cho L2 penalty bằng kiểm định chéo, cần huấn luyện lại mô hình cuối cùng trong tất cả dữ liệu huấn luyện sử dụng `l2_penalty`. Theo cách này, mô hình cuối sẽ được huấn luyện trong toàn bộ tập dữ liệu."]},{"cell_type":"code","metadata":{"id":"yfsV8RKWMH8V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0CdIGVRRMH8b"},"source":["***QUIZ: Với L2 penalty tốt nhất tìm thấy ở trên, hãy huấn luyện một mô hình sử dụng tất cả dữ liệu huấn luyện. RSS trong dữ liệu KIỂM TRA của mô hình với L2 penalty đó là bao nhiêu? ***"]},{"cell_type":"code","metadata":{"id":"WYLheewBMH8c"},"source":[""],"execution_count":null,"outputs":[]}]}